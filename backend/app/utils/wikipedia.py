# -*- coding: utf-8 -*-
import wikipedia
import random
from typing import Dict, List, Optional
from ..models.person import PersonInfo
from ..config.settings import settings


class WikipediaService:
    def __init__(self):
        wikipedia.set_lang(settings.wikipedia_language)
        self._cache: Dict[str, PersonInfo] = {}
        self.famous_people = self._load_famous_people()
    
    def _load_famous_people(self) -> List[str]:
        """ä»æ–‡ä»¶ä¸­åŠ è½½çŸ¥åäººç‰©åˆ—è¡¨"""
        import os
        
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(current_dir)))
        famous_people_file = os.path.join(project_root, "famous_people.txt")
        
        people = []
        try:
            with open(famous_people_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Šè¡Œ
                    if line and not line.startswith('#'):
                        people.append(line)
            
            print(f"ğŸ“š ä»æ–‡ä»¶åŠ è½½äº† {len(people)} ä¸ªçŸ¥åäººç‰©")
            return people
            
        except FileNotFoundError:
            print(f"âš ï¸  æœªæ‰¾åˆ°äººç‰©æ–‡ä»¶ {famous_people_file}ï¼Œä½¿ç”¨é»˜è®¤åˆ—è¡¨")
            # å¤‡ç”¨é»˜è®¤åˆ—è¡¨
            return [
                "Albert Einstein", "Steve Jobs", "Bill Gates", "Elon Musk",
                "Barack Obama", "Donald Trump", "Leonardo da Vinci", "Pablo Picasso",
                "Michael Jackson", "Elvis Presley", "Taylor Swift", "Tom Hanks",
                "Stephen Hawking", "Marie Curie", "Isaac Newton", "Shakespeare",
                "Michael Jordan", "Lionel Messi", "Cristiano Ronaldo",
                "Warren Buffett", "Jeff Bezos", "Mark Zuckerberg"
            ]
        except Exception as e:
            print(f"âŒ åŠ è½½äººç‰©æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return ["Albert Einstein", "Steve Jobs", "Bill Gates"]  # æœ€å°å¤‡ç”¨åˆ—è¡¨
    
    def get_random_person(self) -> str:
        """éšæœºé€‰æ‹©ä¸€ä¸ªçŸ¥åäººç‰©"""
        selected_person = random.choice(self.famous_people)
        print(f"ğŸ¯ éšæœºé€‰æ‹©äº†äººç‰©: {selected_person}")
        return selected_person
    
    def get_people_count(self) -> int:
        """è·å–äººç‰©åˆ—è¡¨æ€»æ•°"""
        return len(self.famous_people)
    
    def get_people_list(self) -> List[str]:
        """è·å–äººç‰©åˆ—è¡¨"""
        return self.famous_people.copy()
    
    def get_person_info(self, person_name: str) -> Optional[PersonInfo]:
        """è·å–äººç‰©ä¿¡æ¯ï¼Œæ”¯æŒç¼“å­˜"""
        if person_name in self._cache:
            return self._cache[person_name]
        
        try:
            # æœç´¢äººç‰©é¡µé¢
            search_results = wikipedia.search(person_name, results=3)
            if not search_results:
                return None
            
            # å°è¯•è·å–æœ€åŒ¹é…çš„é¡µé¢
            page = None
            for result in search_results:
                try:
                    page = wikipedia.page(result)
                    break
                except wikipedia.exceptions.DisambiguationError as e:
                    # å¦‚æœæœ‰æ­§ä¹‰ï¼Œé€‰æ‹©æœ€å¯èƒ½çš„é€‰é¡¹
                    try:
                        page = wikipedia.page(e.options[0])
                        break
                    except:
                        continue
                except:
                    continue
            
            if not page:
                return None
            
            # æå–å…³é”®ä¿¡æ¯
            person_info = self._extract_person_info(page)
            
            # ç¼“å­˜ç»“æœ
            self._cache[person_name] = person_info
            
            return person_info
            
        except Exception as e:
            print(f"Error fetching info for {person_name}: {e}")
            return None
    
    def _extract_person_info(self, page) -> PersonInfo:
        """ä»Wikipediaé¡µé¢æå–äººç‰©ä¿¡æ¯"""
        content = page.content
        summary = page.summary
        
        # æå–åŸºæœ¬ä¿¡æ¯
        categories = page.categories if hasattr(page, 'categories') else []
        
        # ç®€å•çš„ä¿¡æ¯æå–ï¼ˆå¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–ï¼‰
        occupation = self._extract_occupation(content, categories)
        nationality = self._extract_nationality(content)
        birth_date = self._extract_birth_date(content)
        known_for = self._extract_known_for(content, categories)
        
        return PersonInfo(
            name=page.title,
            summary=summary[:500] + "..." if len(summary) > 500 else summary,
            birth_date=birth_date,
            nationality=nationality,
            occupation=occupation,
            known_for=known_for,
            categories=[cat for cat in categories[:10]],  # é™åˆ¶ç±»åˆ«æ•°é‡
            additional_info={}
        )
    
    def _extract_occupation(self, content: str, categories: List[str]) -> List[str]:
        """æå–èŒä¸šä¿¡æ¯"""
        occupations = []
        
        # ä»ç±»åˆ«ä¸­æå–èŒä¸š
        occupation_keywords = [
            "actor", "actress", "singer", "musician", "writer", "author",
            "politician", "scientist", "entrepreneur", "director", "producer",
            "artist", "painter", "athlete", "footballer", "basketball",
            "tennis", "business", "CEO", "founder", "inventor", "physicist",
            "mathematician", "philosopher", "composer", "chef"
        ]
        
        content_lower = content.lower()
        for keyword in occupation_keywords:
            if keyword in content_lower:
                occupations.append(keyword.title())
        
        # ä»ç±»åˆ«ä¸­æå–
        for category in categories:
            for keyword in occupation_keywords:
                if keyword in category.lower():
                    occupations.append(keyword.title())
        
        return list(set(occupations))[:5]  # å»é‡å¹¶é™åˆ¶æ•°é‡
    
    def _extract_nationality(self, content: str) -> Optional[str]:
        """æå–å›½ç±ä¿¡æ¯"""
        # ç®€å•çš„å›½ç±æå–
        countries = [
            "American", "British", "Chinese", "Japanese", "German", "French",
            "Italian", "Spanish", "Russian", "Indian", "Brazilian", "Canadian",
            "Australian", "South Korean", "Mexican", "Argentine", "Dutch",
            "Swedish", "Norwegian", "Danish", "Swiss", "Austrian", "Belgian"
        ]
        
        for country in countries:
            if country.lower() in content.lower():
                return country
        
        return None
    
    def _extract_birth_date(self, content: str) -> Optional[str]:
        """æå–å‡ºç”Ÿæ—¥æœŸï¼ˆç®€å•å®ç°ï¼‰"""
        import re
        
        # å¯»æ‰¾å‡ºç”Ÿæ—¥æœŸæ¨¡å¼
        birth_patterns = [
            r"born (\w+ \d+, \d{4})",
            r"born (\d{4})",
            r"\(born (\w+ \d+, \d{4})\)",
            r"\(born (\d{4})\)"
        ]
        
        for pattern in birth_patterns:
            match = re.search(pattern, content)
            if match:
                return match.group(1)
        
        return None
    
    def _extract_known_for(self, content: str, categories: List[str]) -> List[str]:
        """æå–è‘—åäº‹è¿¹"""
        known_for = []
        
        # ä»å†…å®¹ä¸­æå–å…³é”®è¯
        keywords = [
            "Nobel Prize", "Academy Award", "Grammy", "Emmy", "Tony Award",
            "Olympic", "World Cup", "Super Bowl", "NBA", "FIFA",
            "bestseller", "blockbuster", "hit song", "chart-topping",
            "revolutionary", "groundbreaking", "pioneering", "innovative"
        ]
        
        content_lower = content.lower()
        for keyword in keywords:
            if keyword.lower() in content_lower:
                known_for.append(keyword)
        
        return known_for[:5]  # é™åˆ¶æ•°é‡


# å…¨å±€å®ä¾‹
wikipedia_service = WikipediaService()